{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecd58bd8-c955-4d4b-9446-51f3f1a5d9ff",
   "metadata": {},
   "source": [
    "# Filter dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98ed2311-71e9-42a4-8368-a18316c5f64f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ececf6fa-841d-4c59-8a86-28068a08e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "465acc2a-b959-4498-8732-9adda6045934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Dec 14 00:06:12 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:00:05.0 Off |                  N/A |\n",
      "|  0%   28C    P8    26W / 350W |      8MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  On   | 00000000:00:06.0 Off |                  N/A |\n",
      "|  0%   71C    P2   334W / 350W |  17600MiB / 24576MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  On   | 00000000:00:07.0 Off |                  N/A |\n",
      "|  0%   64C    P2   340W / 350W |  20352MiB / 24576MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce ...  On   | 00000000:00:08.0 Off |                  N/A |\n",
      "|  0%   55C    P2   332W / 350W |  21800MiB / 24576MiB |     92%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA GeForce ...  On   | 00000000:00:09.0 Off |                  N/A |\n",
      "|  0%   56C    P2   331W / 350W |  21764MiB / 24576MiB |     88%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA GeForce ...  On   | 00000000:00:0A.0 Off |                  N/A |\n",
      "|  0%   54C    P2   327W / 350W |  21800MiB / 24576MiB |     92%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA GeForce ...  On   | 00000000:00:0B.0 Off |                  N/A |\n",
      "|  0%   57C    P2   305W / 350W |  21810MiB / 24576MiB |     80%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2010      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    1   N/A  N/A      2010      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    1   N/A  N/A    107646      C   ...vs/poseapi3.10/bin/python     8796MiB |\n",
      "|    1   N/A  N/A    107648      C   ...vs/poseapi3.10/bin/python     8796MiB |\n",
      "|    2   N/A  N/A      2010      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    2   N/A  N/A    107647      C   ...vs/poseapi3.10/bin/python    11548MiB |\n",
      "|    2   N/A  N/A    107649      C   ...vs/poseapi3.10/bin/python     8796MiB |\n",
      "|    3   N/A  N/A      2010      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    3   N/A  N/A    104098      C   ...nvs/controlnet/bin/python    21792MiB |\n",
      "|    4   N/A  N/A      2010      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    4   N/A  N/A    104055      C   ...nvs/controlnet/bin/python    21756MiB |\n",
      "|    5   N/A  N/A      2010      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    5   N/A  N/A    104082      C   ...nvs/controlnet/bin/python    21792MiB |\n",
      "|    6   N/A  N/A      2010      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    6   N/A  N/A    104088      C   ...nvs/controlnet/bin/python    21802MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e70032ad-cddc-498c-ab17-cee69a7aa257",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7eaed569-a6ed-4953-bf0e-323e2e0dc54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import sparknlp\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"PreprocessText\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b432636",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T13:42:59.399740569Z",
     "start_time": "2023-12-13T13:42:58.438424181Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+\n",
      "|                                                        text|\n",
      "+------------------------------------------------------------+\n",
      "|Я мертв, но даже в смерти зол и горд\\n\\nВойна добро и зло...|\n",
      "|Современная гибридная война: кибер-аспект и роль кибербез...|\n",
      "|Поздравляем наших побратимов из Украины с Днем защитника ...|\n",
      "|В ГОСДУМЕ ОБЪЯСНИЛИ, ЗА КАКИЕ ПОСТРОЙКИ НА ДАЧАХ МОЖНО НЕ...|\n",
      "|Шесть человек погибли и четверо пострадали при пожаре в н...|\n",
      "|Благодаря поддержке Дорогого БРАТА-Главы ЧР, Героя России...|\n",
      "|Фронтовая сводка 1 октября \\n\\nНа Запорожском направлении...|\n",
      "|\"На Настю Ивлееву подала в суд жительница Челябинской обл...|\n",
      "|Завершилась очередная трудовая неделя, а значит пришло вр...|\n",
      "|Это Степанакерт. Азербайджанцы свалили крест. Никакого те...|\n",
      "+------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.count(): 1347338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as f\n",
    "\n",
    "def pre_process(df):\n",
    "    \"\"\"\n",
    "    Pre-processes the DataFrame by:\n",
    "    - Removing links\n",
    "    - Removing emojis\n",
    "    - Removing texts less than 10 words\n",
    "    \"\"\"\n",
    "    df = df.select(\"Content\").withColumnRenamed(\"Content\", \"text\")\n",
    "    # Remove links\n",
    "    df = df.withColumn(\"text\", f.regexp_replace(f.col(\"text\"), r\"https?://\\S+\", \"\"))\n",
    "    # Remove emojis\n",
    "    df = df.withColumn(\"text\", f.regexp_replace(f.col(\"text\"), r\"[^\\s\\d\\p{L}\\p{Punct}]\", \"\"))\n",
    "    # Remove texts less than 10 words\n",
    "    df = df.where(f.size(f.split(df.text, \"\\s+\")) >= 50)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = spark.read.csv(\"unsupervised_data.csv\", header=True, multiLine=True)\n",
    "df = pre_process(df)\n",
    "\n",
    "df.show(10, truncate=60)\n",
    "print(f'df.count(): {df.count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2361770b-1f16-4872-8ad8-135e6af96d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.limit(50_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b4bfa5-0db4-4a0a-8172-f7e75026d2bb",
   "metadata": {},
   "source": [
    "# Tokenize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94f4adb9-156d-4574-ad42-28ede0f00c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "weights_path = \"ai-forever/sbert_large_nlu_ru\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(weights_path, cache_dir=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc0c450e-ed79-4eb7-8d60-bf79bdca103a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[101, 119, 26105, 121, 750, 1180, 113, 3286, 4...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[101, 28274, 85501, 844, 29241, 162, 15677, 13...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[101, 16629, 28831, 3726, 87139, 1977, 734, 18...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[101, 113, 3944, 64468, 22305, 121, 681, 2867,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[101, 4439, 1266, 5186, 107, 12648, 10226, 711...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>[101, 16212, 102657, 28967, 12331, 660, 6049, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>[101, 5748, 133, 1049, 939, 12941, 133, 48335,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>[101, 13092, 52182, 177, 93783, 9282, 102351, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>[101, 82645, 1659, 18801, 67124, 458, 133, 194...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>[101, 13092, 52182, 177, 93783, 9282, 102351, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input_ids  \\\n",
       "0      [101, 119, 26105, 121, 750, 1180, 113, 3286, 4...   \n",
       "1      [101, 28274, 85501, 844, 29241, 162, 15677, 13...   \n",
       "2      [101, 16629, 28831, 3726, 87139, 1977, 734, 18...   \n",
       "3      [101, 113, 3944, 64468, 22305, 121, 681, 2867,...   \n",
       "4      [101, 4439, 1266, 5186, 107, 12648, 10226, 711...   \n",
       "...                                                  ...   \n",
       "49995  [101, 16212, 102657, 28967, 12331, 660, 6049, ...   \n",
       "49996  [101, 5748, 133, 1049, 939, 12941, 133, 48335,...   \n",
       "49997  [101, 13092, 52182, 177, 93783, 9282, 102351, ...   \n",
       "49998  [101, 82645, 1659, 18801, 67124, 458, 133, 194...   \n",
       "49999  [101, 13092, 52182, 177, 93783, 9282, 102351, ...   \n",
       "\n",
       "                                          token_type_ids  \\\n",
       "0      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                  ...   \n",
       "49995  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "49996  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "49997  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "49998  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "49999  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                          attention_mask  \n",
       "0      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "4      [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "...                                                  ...  \n",
       "49995  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "49996  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "49997  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "49998  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "49999  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "\n",
       "[50000 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, IntegerType, FloatType\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "weights_path = \"ai-forever/sbert_large_nlu_ru\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(weights_path, cache_dir=\".\")\n",
    "\n",
    "def tokenize_udf(text, max_size = 512):\n",
    "    encoded_inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    input_ids = encoded_inputs[\"input_ids\"].squeeze().tolist()[:max_size]\n",
    "    token_type_ids = encoded_inputs[\"token_type_ids\"].squeeze().tolist()[:max_size]\n",
    "    attention_mask = encoded_inputs[\"attention_mask\"].squeeze().tolist()[:max_size]\n",
    "    return input_ids, token_type_ids, attention_mask\n",
    "\n",
    "tokenize_udf = udf(tokenize_udf, ArrayType(ArrayType(IntegerType())))\n",
    "\n",
    "# Tokenize the data\n",
    "tokenized_df = df.withColumn('data', tokenize_udf(df.text))\n",
    "tokenized_df = tokenized_df.withColumn('input_ids', tokenized_df.data.getItem(0))\n",
    "tokenized_df = tokenized_df.withColumn('token_type_ids', tokenized_df.data.getItem(1))\n",
    "tokenized_df = tokenized_df.withColumn('attention_mask', tokenized_df.data.getItem(2))\n",
    "tokenized_df = tokenized_df.select('input_ids', 'token_type_ids', 'attention_mask')\n",
    "\n",
    "# Access the tokenized data\n",
    "tokenized_path = 'tokenized_df.parquet'\n",
    "tokenized_df.write.mode('overwrite').save(tokenized_path, format='parquet', header=True)\n",
    "\n",
    "tokenized_df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1fe3f5-bdf1-443c-9d76-c1ebc1eb9873",
   "metadata": {},
   "source": [
    "# Mask pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cc21e2f-0cd4-456d-832e-f8589bfc20ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at ai-forever/sbert_large_nlu_ru and are newly initialized: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AutoModelForMaskedLM\n",
    "import torch\n",
    "\n",
    "weights_path = \"ai-forever/sbert_large_nlu_ru\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(weights_path, cache_dir=\".\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(weights_path, cache_dir=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14e648e2-79ee-4084-9351-355d7fd4aa69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tokenized_path = 'tokenized_df.parquet'\n",
    "tokenized_df = spark.read.load(tokenized_path, format='parquet').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c3f787a-602b-4aca-a763-50df73da7a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 45000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "\n",
    "tokenized_ds = Dataset.from_pandas(tokenized_df)\n",
    "tokenized_ds = tokenized_ds.train_test_split(test_size=0.1)\n",
    "tokenized_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a45c690-4ac7-4718-9f57-ddffbb0c859d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# if tokenizer.eos_token is None:\n",
    "#     tokenizer.add_special_tokens({'pad_token': '[EOS]'})\n",
    "#     model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc173280-7aff-4c0c-941d-2c850ff5ce97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4501' max='100000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  4501/100000 29:46 < 10:31:59, 2.52 it/s, Epoch 0.40/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "batch_size = 4\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my_awesome_bert\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\", \n",
    "    eval_steps=0.05, \n",
    "    max_steps=int(400000 / batch_size), \n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    "    report_to=\"tensorboard\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=2*batch_size,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"test\"],\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8417275-4bc2-40ea-b46b-70513587ce52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b597ebfa-f1d5-40b8-aa1a-0b5845746c97",
   "metadata": {},
   "source": [
    "- [Spark NLP Models Hub\n",
    "](https://sparknlp.org/models?task=Embeddings&language=xx&edition=Spark+NLP+5.2&sort=downloads)\n",
    "- [sparknlp embedings](https://sparknlp.org/api/python/reference/autosummary/sparknlp/annotator/embeddings/bert_embeddings/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ab5c761-a419-4290-b93c-3f4c131f2825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Всё дело в буквах, отменить и мы сразу победим)))! Марков М-дак)))'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.text.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "74d16251-561f-4047-9c6c-6e7eda64df5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Всё дело в буквах, то и мы сразу про ) ) )! Марков ин - дак ) ) )']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug.augment(data.text.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "474ed45a-2b22-4a31-930c-283b3c14263e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Я мертв, но даже в гибели зол и горд Война добро и зло не выбирает. Есть мысли, ручка, воинский билет. А понимаю наша рота погибает Я знала, что итогом будет смерть. Что написать врагу чтобы он понял, И смысл строк оставил на душе Солдат России это правды воин Хотя сейчас и легкая мишень. Живым меня ты точно не возьмёшь, А безоружным пред тобою не буду И если ты в окоп ко мне зайдёшь То точно позабудь о слове чудо Я буду в клочья я тебя нацист Я вечно и рядом, я как ветер Я твой последний в жизни экзорцист я СВОй читай в моем билете. Там знаю что Победа, наш трофей, Её только давно нам завещал. Строкой то говорю СВОей Чтоб враг ее пред смертью вспоминал! Я сын страны и в убеждениях твёрд У всех солдат в бою СВОя мессия Я мертв, но даже в смерти зол и горд Что я погиб за Правду и Её! Лик Д. С.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug.augment(data.text.iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e553f12-2161-4f7e-a427-8b83abe9e38e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
