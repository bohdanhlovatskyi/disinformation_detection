{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b9eef6c-7177-4074-a7b1-c3d407ff668d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import sparknlp\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.clustering import LDA\n",
    "from pyspark.ml.feature import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "510cc4c4-e141-4f68-9897-59a3b0419ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk 17.0.7 2023-04-18\n",
      "OpenJDK Runtime Environment (build 17.0.7+7-Ubuntu-0ubuntu120.04)\n",
      "OpenJDK 64-Bit Server VM (build 17.0.7+7-Ubuntu-0ubuntu120.04, mixed mode, sharing)\n"
     ]
    }
   ],
   "source": [
    "!java --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aeba59f7-ad6d-48c1-9b94-10f3d3c313b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/mnt/vol_b/miniconda3/envs/poseapi3.10/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/ubuntu/.ivy2/cache\n",
      "The jars for the packages stored in: /home/ubuntu/.ivy2/jars\n",
      "com.johnsnowlabs.nlp#spark-nlp_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-7123477b-55f6-4baa-a383-c64813b6388b;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.johnsnowlabs.nlp#spark-nlp_2.12;5.2.0 in central\n",
      "\tfound com.typesafe#config;1.4.2 in central\n",
      "\tfound org.rocksdb#rocksdbjni;6.29.5 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.828 in central\n",
      "\tfound com.github.universal-automata#liblevenshtein;3.0.0 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.0.0-beta-3 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.0.0-beta-3 in central\n",
      "\tfound com.google.code.gson#gson;2.3 in central\n",
      "\tfound it.unimi.dsi#fastutil;7.0.12 in central\n",
      "\tfound org.projectlombok#lombok;1.16.8 in central\n",
      "\tfound com.google.cloud#google-cloud-storage;2.20.1 in central\n",
      "\tfound com.google.guava#guava;31.1-jre in central\n",
      "\tfound com.google.guava#failureaccess;1.0.1 in central\n",
      "\tfound com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.18.0 in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;1.3 in central\n",
      "\tfound com.google.http-client#google-http-client;1.43.0 in central\n",
      "\tfound io.opencensus#opencensus-contrib-http-util;0.31.1 in central\n",
      "\tfound com.google.http-client#google-http-client-jackson2;1.43.0 in central\n",
      "\tfound com.google.http-client#google-http-client-gson;1.43.0 in central\n",
      "\tfound com.google.api-client#google-api-client;2.2.0 in central\n",
      "\tfound commons-codec#commons-codec;1.15 in central\n",
      "\tfound com.google.oauth-client#google-oauth-client;1.34.1 in central\n",
      "\tfound com.google.http-client#google-http-client-apache-v2;1.43.0 in central\n",
      "\tfound com.google.apis#google-api-services-storage;v1-rev20220705-2.0.0 in central\n",
      "\tfound com.google.code.gson#gson;2.10.1 in central\n",
      "\tfound com.google.cloud#google-cloud-core;2.12.0 in central\n",
      "\tfound io.grpc#grpc-context;1.53.0 in central\n",
      "\tfound com.google.auto.value#auto-value-annotations;1.10.1 in central\n",
      "\tfound com.google.auto.value#auto-value;1.10.1 in central\n",
      "\tfound javax.annotation#javax.annotation-api;1.3.2 in central\n",
      "\tfound commons-logging#commons-logging;1.2 in central\n",
      "\tfound com.google.cloud#google-cloud-core-http;2.12.0 in central\n",
      "\tfound com.google.http-client#google-http-client-appengine;1.43.0 in central\n",
      "\tfound com.google.api#gax-httpjson;0.108.2 in central\n",
      "\tfound com.google.cloud#google-cloud-core-grpc;2.12.0 in central\n",
      "\tfound io.grpc#grpc-alts;1.53.0 in central\n",
      "\tfound io.grpc#grpc-grpclb;1.53.0 in central\n",
      "\tfound org.conscrypt#conscrypt-openjdk-uber;2.5.2 in central\n",
      "\tfound io.grpc#grpc-auth;1.53.0 in central\n",
      "\tfound io.grpc#grpc-protobuf;1.53.0 in central\n",
      "\tfound io.grpc#grpc-protobuf-lite;1.53.0 in central\n",
      "\tfound io.grpc#grpc-core;1.53.0 in central\n",
      "\tfound com.google.api#gax;2.23.2 in central\n",
      "\tfound com.google.api#gax-grpc;2.23.2 in central\n",
      "\tfound com.google.auth#google-auth-library-credentials;1.16.0 in central\n",
      "\tfound com.google.auth#google-auth-library-oauth2-http;1.16.0 in central\n",
      "\tfound com.google.api#api-common;2.6.2 in central\n",
      "\tfound io.opencensus#opencensus-api;0.31.1 in central\n",
      "\tfound com.google.api.grpc#proto-google-iam-v1;1.9.2 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.21.12 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.21.12 in central\n",
      "\tfound com.google.api.grpc#proto-google-common-protos;2.14.2 in central\n",
      "\tfound org.threeten#threetenbp;1.6.5 in central\n",
      "\tfound com.google.api.grpc#proto-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.api.grpc#grpc-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.api.grpc#gapic-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.14.2 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound io.grpc#grpc-api;1.53.0 in central\n",
      "\tfound io.grpc#grpc-stub;1.53.0 in central\n",
      "\tfound org.checkerframework#checker-qual;3.31.0 in central\n",
      "\tfound io.perfmark#perfmark-api;0.26.0 in central\n",
      "\tfound com.google.android#annotations;4.1.1.4 in central\n",
      "\tfound org.codehaus.mojo#animal-sniffer-annotations;1.22 in central\n",
      "\tfound io.opencensus#opencensus-proto;0.2.0 in central\n",
      "\tfound io.grpc#grpc-services;1.53.0 in central\n",
      "\tfound com.google.re2j#re2j;1.6 in central\n",
      "\tfound io.grpc#grpc-netty-shaded;1.53.0 in central\n",
      "\tfound io.grpc#grpc-googleapis;1.53.0 in central\n",
      "\tfound io.grpc#grpc-xds;1.53.0 in central\n",
      "\tfound com.navigamez#greex;1.0 in central\n",
      "\tfound dk.brics.automaton#automaton;1.11-8 in central\n",
      "\tfound com.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.4 in central\n",
      "\tfound com.microsoft.onnxruntime#onnxruntime;1.16.3 in central\n",
      ":: resolution report :: resolve 2775ms :: artifacts dl 136ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.828 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.14.2 from central in [default]\n",
      "\tcom.github.universal-automata#liblevenshtein;3.0.0 from central in [default]\n",
      "\tcom.google.android#annotations;4.1.1.4 from central in [default]\n",
      "\tcom.google.api#api-common;2.6.2 from central in [default]\n",
      "\tcom.google.api#gax;2.23.2 from central in [default]\n",
      "\tcom.google.api#gax-grpc;2.23.2 from central in [default]\n",
      "\tcom.google.api#gax-httpjson;0.108.2 from central in [default]\n",
      "\tcom.google.api-client#google-api-client;2.2.0 from central in [default]\n",
      "\tcom.google.api.grpc#gapic-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#grpc-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-common-protos;2.14.2 from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-iam-v1;1.9.2 from central in [default]\n",
      "\tcom.google.apis#google-api-services-storage;v1-rev20220705-2.0.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-credentials;1.16.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-oauth2-http;1.16.0 from central in [default]\n",
      "\tcom.google.auto.value#auto-value;1.10.1 from central in [default]\n",
      "\tcom.google.auto.value#auto-value-annotations;1.10.1 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core-grpc;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core-http;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-storage;2.20.1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.10.1 from central in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.18.0 from central in [default]\n",
      "\tcom.google.guava#failureaccess;1.0.1 from central in [default]\n",
      "\tcom.google.guava#guava;31.1-jre from central in [default]\n",
      "\tcom.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava from central in [default]\n",
      "\tcom.google.http-client#google-http-client;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-apache-v2;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-appengine;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-gson;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-jackson2;1.43.0 from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;1.3 from central in [default]\n",
      "\tcom.google.oauth-client#google-oauth-client;1.34.1 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.21.12 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.21.12 from central in [default]\n",
      "\tcom.google.re2j#re2j;1.6 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#spark-nlp_2.12;5.2.0 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.4 from central in [default]\n",
      "\tcom.microsoft.onnxruntime#onnxruntime;1.16.3 from central in [default]\n",
      "\tcom.navigamez#greex;1.0 from central in [default]\n",
      "\tcom.typesafe#config;1.4.2 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.15 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.2 from central in [default]\n",
      "\tdk.brics.automaton#automaton;1.11-8 from central in [default]\n",
      "\tio.grpc#grpc-alts;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-api;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-auth;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-context;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-core;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-googleapis;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-grpclb;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-netty-shaded;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-protobuf;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-protobuf-lite;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-services;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-stub;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-xds;1.53.0 from central in [default]\n",
      "\tio.opencensus#opencensus-api;0.31.1 from central in [default]\n",
      "\tio.opencensus#opencensus-contrib-http-util;0.31.1 from central in [default]\n",
      "\tio.opencensus#opencensus-proto;0.2.0 from central in [default]\n",
      "\tio.perfmark#perfmark-api;0.26.0 from central in [default]\n",
      "\tit.unimi.dsi#fastutil;7.0.12 from central in [default]\n",
      "\tjavax.annotation#javax.annotation-api;1.3.2 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.31.0 from central in [default]\n",
      "\torg.codehaus.mojo#animal-sniffer-annotations;1.22 from central in [default]\n",
      "\torg.conscrypt#conscrypt-openjdk-uber;2.5.2 from central in [default]\n",
      "\torg.projectlombok#lombok;1.16.8 from central in [default]\n",
      "\torg.rocksdb#rocksdbjni;6.29.5 from central in [default]\n",
      "\torg.threeten#threetenbp;1.6.5 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcom.google.protobuf#protobuf-java-util;3.0.0-beta-3 by [com.google.protobuf#protobuf-java-util;3.21.12] in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.0.0-beta-3 by [com.google.protobuf#protobuf-java;3.21.12] in [default]\n",
      "\tcom.google.code.gson#gson;2.3 by [com.google.code.gson#gson;2.10.1] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   75  |   0   |   0   |   3   ||   72  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-7123477b-55f6-4baa-a383-c64813b6388b\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 72 already retrieved (0kB/25ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/12/09 12:56:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c3d0da3-7997-48f3-94fa-11de2eae5bea",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpyspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "pyspark.version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3fd1728-0d45-423f-8c66-679f8a05d301",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 15\n",
    "lda = LDA(k=num_topics, maxIter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878872e6-5df8-48c9-bac3-e6bdcb9c53cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a662eb8-11ff-4831-a642-24bd7ec6517e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ChannelName</th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>krovatka_luki</td>\n",
       "      <td>2023-10-01 13:46:39.000</td>\n",
       "      <td>Ну вот со всех подряд и начинай😁</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dumerz</td>\n",
       "      <td>2023-10-01 19:25:23.000</td>\n",
       "      <td>да</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>moscowtam</td>\n",
       "      <td>2023-10-01 17:41:32.000</td>\n",
       "      <td>Смотрела званый ужин?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uavdevchat</td>\n",
       "      <td>2023-10-01 15:55:10.000</td>\n",
       "      <td>хера тебя штырит. Это рептилоиды.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kadyrov_95chat</td>\n",
       "      <td>2023-10-01 12:39:54.000</td>\n",
       "      <td>Мира и процветания нашей Республике</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ChannelName                     Date   \n",
       "0   krovatka_luki  2023-10-01 13:46:39.000  \\\n",
       "1          dumerz  2023-10-01 19:25:23.000   \n",
       "2       moscowtam  2023-10-01 17:41:32.000   \n",
       "3      uavdevchat  2023-10-01 15:55:10.000   \n",
       "4  kadyrov_95chat  2023-10-01 12:39:54.000   \n",
       "\n",
       "                               Content  \n",
       "0     Ну вот со всех подряд и начинай😁  \n",
       "1                                   да  \n",
       "2                Смотрела званый ужин?  \n",
       "3    хера тебя штырит. Это рептилоиды.  \n",
       "4  Мира и процветания нашей Республике  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"unsupervised_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea475cc0-94d4-4438-a853-671eaa3004be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_df = df[:1000]\n",
    "reduced_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6676b5e8-7ce7-4c08-8992-22fff3268794",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df.to_csv(\"un_subset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "09078600-e093-4ff5-9ca8-7619e65ee988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "\n",
    "def remove_urls(text):\n",
    "    return re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "\n",
    "def remove_emojis(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = remove_urls(text)\n",
    "    text = remove_emojis(text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def multiline_csv_reader(file_path, max_num=100):\n",
    "    with open(file_path, 'r', newline='') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        headers = next(csv_reader)\n",
    "        \n",
    "        i=0\n",
    "        for row in csv_reader:\n",
    "            \n",
    "            if i >= max_num:\n",
    "                break\n",
    "            text = row[-1]\n",
    "            text = preprocess_text(text)\n",
    "            if text:\n",
    "                i += 1\n",
    "                yield text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f6d954ff-0eb2-4f16-83c3-4191d9c86300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ну вот со всех подряд и начинай\n"
     ]
    }
   ],
   "source": [
    "for elm in multiline_csv_reader(\"un_subset.csv\"):\n",
    "    print(elm)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5163c06-f120-4f56-8e94-5a1c80912f8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f1fbb999-80fb-4c90-9915-0e7f96c0c79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = spark.read.format(\"csv\").option(\"header\",True).load(\"un_subset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8103f1b0-c1ad-4cb1-a972-ea35b349c20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[ChannelName: string, Date: string, Content: string]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4850ceb0-d5bb-471c-a24a-50af7658d914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+--------------------+\n",
      "|    ChannelName|                Date|             Content|\n",
      "+---------------+--------------------+--------------------+\n",
      "|  krovatka_luki|2023-10-01 13:46:...|Ну вот со всех по...|\n",
      "|         dumerz|2023-10-01 19:25:...|                  да|\n",
      "|      moscowtam|2023-10-01 17:41:...|Смотрела званый у...|\n",
      "|     uavdevchat|2023-10-01 15:55:...|хера тебя штырит....|\n",
      "| kadyrov_95chat|2023-10-01 12:39:...|Мира и процветани...|\n",
      "|screen_and_link|2023-10-01 13:22:...|              Алехин|\n",
      "| kadyrov_95chat|2023-10-01 12:37:...|            👍 удачи|\n",
      "|  putin_sobchak|2023-10-01 05:11:...|https://www.youtu...|\n",
      "|  putin_sobchak|2023-10-01 09:30:...|https://www.youtu...|\n",
      "|  putin_sobchak|2023-10-01 05:13:...|https://www.youtu...|\n",
      "|hze7fcbzsdhnzm0|2023-10-01 06:08:...|         Цирк шапито|\n",
      "|  putin_sobchak|2023-10-01 08:44:...|https://www.youtu...|\n",
      "|  putin_sobchak|2023-10-01 05:02:...|https://www.youtu...|\n",
      "|  putin_sobchak|2023-10-01 08:58:...|https://www.youtu...|\n",
      "|  putin_sobchak|2023-10-01 05:14:...|https://www.youtu...|\n",
      "|  putin_sobchak|2023-10-01 09:41:...|https://www.youtu...|\n",
      "|  putin_sobchak|2023-10-01 05:00:...|https://www.youtu...|\n",
      "|  putin_sobchak|2023-10-01 05:25:...|https://www.youtu...|\n",
      "|  putin_sobchak|2023-10-01 13:21:...|https://www.youtu...|\n",
      "|  putin_sobchak|2023-10-01 09:35:...|https://www.youtu...|\n",
      "+---------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "77a3993e-7ec4-4647-a3a3-8bb33c30d858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sdf = sdf.withColumn(\"Content\", pyspark.sql.functions.array(sdf[\"Content\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4526b072-9051-4b6f-85ae-6f36f1fd75a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stopwords_ru download started this may take some time.\n",
      "Approximate size to download 2.9 KB\n",
      "[OK!]\n",
      "lemma download started this may take some time.\n",
      "Approximate size to download 1.3 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"Content\") \\\n",
    "    .setOutputCol(\"document\") \\\n",
    "    .setCleanupMode(\"shrink\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "  .setInputCols([\"document\"]) \\\n",
    "  .setOutputCol(\"token\")\n",
    "\n",
    "normalizer = Normalizer() \\\n",
    "    .setInputCols([\"token\"]) \\\n",
    "    .setOutputCol(\"normalized\")\n",
    "\n",
    "stopwords_cleaner = StopWordsCleaner()\\\n",
    "      .pretrained('stopwords_ru', 'ru')\\\n",
    "      .setInputCols(\"normalized\")\\\n",
    "      .setOutputCol(\"cleanTokens\")\\\n",
    "      .setCaseSensitive(False)\n",
    "\n",
    "lemmatizer = LemmatizerModel\\\n",
    "    .pretrained(\"lemma\", \"ru\") \\\n",
    "    .setInputCols([\"cleanTokens\"]) \\\n",
    "    .setOutputCol(\"lemma\")\n",
    "\n",
    "finisher = Finisher() \\\n",
    "    .setInputCols([\"lemma\"]) \\\n",
    "    .setOutputCols([\"tokens\"]) \\\n",
    "    .setOutputAsArray(True) \\\n",
    "    .setCleanAnnotations(False)\n",
    "\n",
    "nlp_pipeline = Pipeline(\n",
    "    stages=[\n",
    "            document_assembler, \n",
    "            tokenizer,\n",
    "            normalizer,\n",
    "            stopwords_cleaner, \n",
    "            lemmatizer,\n",
    "            finisher\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "37b396eb-c012-4b88-aa3f-e02389eba29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_model = nlp_pipeline.fit(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a74bed44-ae3a-4a34-ba52-b5a6e92ccd08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DocumentAssembler_be4637c717ee,\n",
       " REGEX_TOKENIZER_63d0ce2e9d70,\n",
       " NORMALIZER_a94001f1d001,\n",
       " STOPWORDS_CLEANER_3187062cd9db,\n",
       " LEMMATIZER_59ad4a12c2e7,\n",
       " Finisher_b88cc9c66ab1]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_model.stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d16f53bc-a42f-4ad5-996e-f8883a76db21",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = nlp_model.transform(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "810cd2c5-cb20-4a25-94a2-48e900edbcca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|              tokens|\n",
      "+--------------------+\n",
      "|  [подряд, начинать]|\n",
      "|                  []|\n",
      "|[Смотрела, званый...|\n",
      "|[хера, штырит, ре...|\n",
      "|[процветание, наш...|\n",
      "|            [Алехин]|\n",
      "|             [удача]|\n",
      "|[httpswwwyoutubec...|\n",
      "|[httpswwwyoutubec...|\n",
      "|[httpswwwyoutubec...|\n",
      "|      [цирк, шапито]|\n",
      "|[httpswwwyoutubec...|\n",
      "|[httpswwwyoutubec...|\n",
      "|[httpswwwyoutubec...|\n",
      "|[httpswwwyoutubec...|\n",
      "|[httpswwwyoutubec...|\n",
      "|[httpswwwyoutubec...|\n",
      "|[httpswwwyoutubec...|\n",
      "|[httpswwwyoutubec...|\n",
      "|[httpswwwyoutubec...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokens_df = processed_df.select('tokens').limit(10000)\n",
    "tokens_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "68ee4074-7601-4256-9960-7e253adb1378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(tokens=['подряд', 'начинать']),\n",
       " Row(tokens=[]),\n",
       " Row(tokens=['Смотрела', 'званый', 'ужин']),\n",
       " Row(tokens=['хера', 'штырит', 'рептилоиды']),\n",
       " Row(tokens=['процветание', 'нашей', 'Республика'])]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_df.select(\"tokens\").take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a59a800-e021-4393-bb0e-81b5b757757c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15186a31-f456-4600-be59-7d75c5b40244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "90d0f6fc-674a-4b9e-92d9-642c974d1750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[tokens: array<string>, features: vector]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(inputCol=\"tokens\", outputCol=\"features\", vocabSize=10000, minDF=3.0)\n",
    "cv_model = cv.fit(tokens_df)\n",
    "vectorized_tokens = cv_model.transform(tokens_df)\n",
    "vectorized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552572e2-59bb-4e63-b993-85edf7b4a90d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3588df4a-3564-4351-b789-daea1e6e829d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 15\n",
    "lda = LDA(k=num_topics, maxIter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "03b34b38-8154-448f-88a3-75ba66f08194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.2 ms, sys: 4.19 ms, total: 19.4 ms\n",
      "Wall time: 2.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = lda.fit(vectorized_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a6dd6434-495f-49d7-b2aa-7225abf55243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------------------------------------------------------------------------------+\n",
      "|topic|words                                                                                   |\n",
      "+-----+----------------------------------------------------------------------------------------+\n",
      "|0    |[защитник, воинам, позиция, Успех, the, тема, of, that, страна, получиться]             |\n",
      "|1    |[воздух, буква, позиция, дело, идти, войла, воинам, TRANSLATION, стараться, боевой]     |\n",
      "|2    |[Украина, РФ, работать, нужный, стать, делать, хьо, судить, победить, выполнение]       |\n",
      "|3    |[писать, говорить, походу, reklama, iltimos, tarqatmang, регион, хороший, цена, поднять]|\n",
      "|4    |[ночь, пусть, благой, хороший, мусульманин, быстро, примета, Аллах, новость, дело]      |\n",
      "|5    |[живой, and, получать, объект, is, наблюдать, идти, готовый, интересный, главное]       |\n",
      "|6    |[Дала, йойла, беркате, бойла, бойцам, удача, наш, таьхье, вай, желать]                  |\n",
      "|7    |[канал, никто, группа, знать, хотеть, дорогой, мир, нашей, каждый, должен]              |\n",
      "|8    |[страна, нахуй, идти, факт, стать, победить, утро, понимать, нашей, ввести]             |\n",
      "|9    |[Россия, правильный, власть, ввести, наш, факт, объект, делать, военный, АХМАТ]         |\n",
      "|10   |[очередной, русский, идти, reklama, работа, алаш, выполнение, лучший, огромный, Im]     |\n",
      "|11   |[Заразить, красивый, рука, защитник, стоить, добрый, новость, воинам, воздух, жить]     |\n",
      "|12   |[успех, удача, благодарность, Присоединяюсь, слово, желать, благо, дело, задача, Желаем]|\n",
      "|13   |[Дала, аьтто, бойл, война, бойла, рост, вопрос, стоить, промышленный, аьтту]            |\n",
      "|14   |[сила, Ахмат, видеть, I, мочь, a, ответить, кстати, to, смотреть]                       |\n",
      "+-----+----------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "vocab = cv_model.vocabulary\n",
    "topics = model.describeTopics()   \n",
    "topics_rdd = topics.rdd\n",
    "topics_words = topics_rdd \\\n",
    "       .map(lambda row: row['termIndices']) \\\n",
    "       .map(lambda idx_list: [vocab[idx] for idx in idx_list]) \\\n",
    "       .collect()\n",
    "\n",
    "def get_words(idx_list):\n",
    "    return [vocab[idx] for idx in idx_list]\n",
    "\n",
    "udf_get_words = udf(get_words, ArrayType(StringType()))\n",
    "topics = topics.withColumn(\"words\", udf_get_words(topics.termIndices))\n",
    "\n",
    "topics_df = topics.select(\"topic\", \"words\")\n",
    "\n",
    "topics_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767acd0e-436d-4415-97db-f0c88c85450b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
